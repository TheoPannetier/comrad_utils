Running dd_ML for ddmodel = 4, siga = 0.3, sigk = 4
Reading /data/p282688/fabrika/comrad_data/phylos/comrad_phylos_sigk_4_siga_0.3.rds 

Tree 1 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -573.2972 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 2 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -648.6821 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 3 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -549.6097 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 4 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -538.0402 
Cycle 1
Error : in ‘subplex’: missing value where TRUE/FALSE needed
Tree 5 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -599.9607 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 6 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -527.7365 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 7 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -499.9509 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 8 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -592.5338 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 9 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -561.6826 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Tree 10 / 10 
You are optimizing lambda mu K 
You are fixing nothing 
Optimizing the likelihood - this may take a while. 
The loglikelihood for the initial parameter values is -608.0024 
Cycle 1
Error : in ‘subplex’: The requested tolerance (tol=1e-07) is too small for mxrej=10.
Saving at /data/p282688/fabrika/comrad_data/DDD_ml/DDD_ddmodel_4_sigk_4_siga_0.3.rds 


###############################################################################
Peregrine Cluster
Job 17586227 for user 'p282688'
Finished at: Fri Jan 22 17:55:53 CET 2021

Job details:
============

Job ID              : 17586227
Name                : ddd_ml_hpc.bash
User                : p282688
Partition           : gelifes
Nodes               : pg-node224
Number of Nodes     : 1
Cores               : 1
State               : COMPLETED
Submit              : 2021-01-22T17:12:12
Start               : 2021-01-22T17:12:13
End                 : 2021-01-22T17:55:53
Reserved walltime   : 15:28:00
Used walltime       : 00:43:40
Used CPU time       : 00:43:34 (efficiency: 99.79%)
% User (Computation): 99.59%
% System (I/O)      :  0.41%
Mem reserved        : 2000M/core
Max Mem used        : 214.91M (pg-node224)
Max Disk Write      : 112.64K (pg-node224)
Max Disk Read       : 1.87M (pg-node224)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/introduction/scientific_output

################################################################################
